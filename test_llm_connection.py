#!/usr/bin/env python3
"""
æµ‹è¯•LLMè¿æ¥
"""

import sys
import os
import asyncio

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from services.llm_service import llm_service

async def test_llm_connection():
    """æµ‹è¯•LLMè¿æ¥å’ŒåŸºæœ¬åŠŸèƒ½"""
    try:
        print("ğŸ” æµ‹è¯•LLMè¿æ¥...")
        
        # æµ‹è¯•æ–‡æ¡£å†…å®¹
        test_content = """
        å…¬å¸åç§°ï¼šæµ‹è¯•ç§‘æŠ€æœ‰é™å…¬å¸
        è”ç³»äººï¼šå¼ ä¸‰
        è”ç³»ç”µè¯ï¼š13800138000
        é‚®ç®±ï¼šzhangsan@test.com
        æ³¨å†Œèµ„æœ¬ï¼š1000ä¸‡å…ƒ
        ç»è¥èŒƒå›´ï¼šè½¯ä»¶å¼€å‘ã€æŠ€æœ¯æœåŠ¡
        ä¸»è¦äº§å“ï¼šä¼ä¸šç®¡ç†è½¯ä»¶
        """
        
        # è°ƒç”¨LLMåˆ†æ
        result = await llm_service.analyze_document(
            content=test_content,
            merchant_type="factory"
        )
        
        if result["success"]:
            print("âœ… LLMè¿æ¥æˆåŠŸ!")
            print(f"ğŸ“Š å¤„ç†æ—¶é—´: {result['processing_time']:.2f}ç§’")
            print(f"ğŸ¯ æ•´ä½“ç½®ä¿¡åº¦: {result['overall_confidence']:.2f}")
            print(f"ğŸ“ æå–å­—æ®µæ•°: {len(result['suggestions'])}")
            
            # æ˜¾ç¤ºå‰3ä¸ªå»ºè®®
            for i, suggestion in enumerate(result['suggestions'][:3]):
                print(f"  {i+1}. {suggestion['field_name']}: {suggestion['suggested_value']} (ç½®ä¿¡åº¦: {suggestion['confidence']:.2f})")
        else:
            print("âŒ LLMåˆ†æå¤±è´¥:")
            print(f"é”™è¯¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
    except Exception as e:
        print(f"âŒ LLMè¿æ¥æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    asyncio.run(test_llm_connection())
