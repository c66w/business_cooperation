"""
LLMæ™ºèƒ½åˆ†ææœåŠ¡ - æ”¯æŒåˆ†é˜¶æ®µã€åˆ†å•†å®¶ç±»å‹çš„æ™ºèƒ½è¡¨å•å¡«å†™
"""

import json
import time
from typing import Dict, Any, List
from loguru import logger
import openai
from config.settings import LLM_CONFIG

class LLMService:
    """LLMæ™ºèƒ½åˆ†ææœåŠ¡ç±»"""

    def __init__(self):
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯"""
        try:
            self.client = openai.OpenAI(
                api_key=LLM_CONFIG["api_key"],
                base_url=LLM_CONFIG["base_url"]
            )
            self.model = LLM_CONFIG["model"]
            self.temperature = LLM_CONFIG["temperature"]
            self.max_tokens = LLM_CONFIG["max_tokens"]

            # å•†å®¶ç±»å‹æ˜ å°„
            self.merchant_type_names = {
                "factory": "ç”Ÿäº§å·¥å‚",
                "brand": "å“ç‰Œå•†",
                "agent": "ä»£ç†å•†",
                "dealer": "ç»é”€å•†",
                "operator": "ä»£è¿è¥å•†"
            }

            logger.info(f"LLMå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ - æ¨¡å‹: {self.model}, æœåŠ¡åœ°å€: {LLM_CONFIG['base_url']}")
        except Exception as e:
            logger.error(f"LLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def analyze_basic_info(self, content: str, current_data: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        åˆ†æåŸºç¡€ä¿¡æ¯é˜¶æ®µ - æå–å…¬å¸åŸºæœ¬ä¿¡æ¯

        Args:
            content: æ–‡æ¡£æ–‡æœ¬å†…å®¹
            current_data: å½“å‰å·²å¡«å†™çš„æ•°æ®

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        try:
            start_time = time.time()

            # æ„å»ºåŸºç¡€ä¿¡æ¯æç¤ºè¯
            prompt = self._build_basic_info_prompt(content, current_data)

            # è°ƒç”¨LLM
            response = await self._call_llm(prompt)

            # è§£æå“åº”
            suggestions = self._parse_basic_info_response(response)

            processing_time = time.time() - start_time

            return {
                "success": True,
                "suggestions": suggestions,
                "processing_time": processing_time,
                "overall_confidence": self._calculate_overall_confidence(suggestions),
                "stage": "basic_info"
            }

        except Exception as e:
            logger.error(f"åŸºç¡€ä¿¡æ¯åˆ†æå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "suggestions": [],
                "stage": "basic_info"
            }

    async def analyze_detailed_info(self, content: str, merchant_type: str, current_data: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        åˆ†æè¯¦ç»†ä¿¡æ¯é˜¶æ®µ - æ ¹æ®å•†å®¶ç±»å‹æå–ç‰¹å®šå­—æ®µ

        Args:
            content: æ–‡æ¡£æ–‡æœ¬å†…å®¹
            merchant_type: å•†å®¶ç±»å‹
            current_data: å½“å‰å·²å¡«å†™çš„æ•°æ®

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        try:
            start_time = time.time()

            # æ„å»ºè¯¦ç»†ä¿¡æ¯æç¤ºè¯
            prompt = self._build_detailed_info_prompt(content, merchant_type, current_data)

            # è°ƒç”¨LLM
            response = await self._call_llm(prompt)

            # è§£æå“åº”
            suggestions = self._parse_detailed_info_response(response, merchant_type)

            processing_time = time.time() - start_time

            return {
                "success": True,
                "suggestions": suggestions,
                "processing_time": processing_time,
                "overall_confidence": self._calculate_overall_confidence(suggestions),
                "stage": "detailed_info",
                "merchant_type": merchant_type
            }

        except Exception as e:
            logger.error(f"è¯¦ç»†ä¿¡æ¯åˆ†æå¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "suggestions": [],
                "stage": "detailed_info",
                "merchant_type": merchant_type
            }

    async def analyze_document(self, content: str, merchant_type: str, structured_content: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        å…¼å®¹æ€§æ–¹æ³• - ä¿æŒå‘åå…¼å®¹
        """
        logger.warning("ä½¿ç”¨äº†åºŸå¼ƒçš„analyze_documentæ–¹æ³•ï¼Œå»ºè®®ä½¿ç”¨analyze_basic_infoæˆ–analyze_detailed_info")
        return await self.analyze_detailed_info(content, merchant_type, structured_content)
    
    def _build_basic_info_prompt(self, content: str, current_data: Dict[str, Any] = None) -> str:
        """æ„å»ºåŸºç¡€ä¿¡æ¯é˜¶æ®µçš„æç¤ºè¯"""

        current_info = ""
        if current_data:
            current_info = f"\nå½“å‰å·²å¡«å†™çš„ä¿¡æ¯ï¼š\n{json.dumps(current_data, ensure_ascii=False, indent=2)}\n"

        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å•†å®¶ç”³è¯·ä¿¡æ¯æå–åŠ©æ‰‹ã€‚è¯·ä»ä»¥ä¸‹æ–‡æ¡£å†…å®¹ä¸­æå–å•†å®¶çš„åŸºç¡€ä¿¡æ¯ã€‚

æ–‡æ¡£å†…å®¹ï¼š
{content[:3000]}
{current_info}
è¯·æå–ä»¥ä¸‹åŸºç¡€å­—æ®µä¿¡æ¯ï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ã€‚å¦‚æœæŸä¸ªå­—æ®µåœ¨æ–‡æ¡£ä¸­æ‰¾ä¸åˆ°ï¼Œè¯·è®¾ç½®ä¸ºnullï¼š

{{
    "company_name": "å…¬å¸å…¨ç§°ï¼ˆè¥ä¸šæ‰§ç…§ä¸Šçš„åç§°ï¼‰",
    "contact_name": "è”ç³»äººå§“å",
    "contact_phone": "è”ç³»ç”µè¯ï¼ˆæ‰‹æœºå·ï¼‰",
    "contact_email": "è”ç³»é‚®ç®±",
    "product_category": "äº§å“å“ç±»ï¼ˆä»ä»¥ä¸‹é€‰æ‹©ï¼š3Cæ•°ç å®¶ç”µã€æœ¬åœ°ç”Ÿæ´»ã€å® ç‰©ç”Ÿæ´»ã€æœé¥°ç®±åŒ…ã€ä¸ªæŠ¤å®¶æ¸…ã€å®¶å±…ç™¾è´§ã€ç¤¼å“æ–‡åˆ›ã€è¿åŠ¨æˆ·å¤–ã€å®¶è£…å®¶å…·ã€é…’æ°´ã€ç¾å¦†ã€æ¯å©´ç«¥è£…ã€æ±½æ‘©ç”Ÿæ´»ã€ç”Ÿé²œã€é£Ÿå“é¥®æ–™ã€æ‰‹è¡¨é…é¥°ã€å›¾ä¹¦æ•™è‚²ã€ç©å…·ä¹å™¨ã€è™šæ‹Ÿå……å€¼ã€ç å®æ–‡ç©ã€æ»‹è¡¥ä¿å¥ã€å…¶å®ƒï¼‰",
    "specific_products": "å…·ä½“äº§å“æè¿°",
    "cooperation_requirements": "å’Œé¥æœ›åˆä½œè¯‰æ±‚ï¼ˆæè¿°åˆä½œéœ€æ±‚ï¼‰",
    "industry_operator_contact": "å¯¹æ¥è¡Œä¸šè¿è¥èŠ±åï¼ˆæ²¡æœ‰å¡«æ— ï¼‰"
}}

æå–è¦æ±‚ï¼š
1. å…¬å¸åç§°å¿…é¡»æ˜¯å®Œæ•´çš„ä¼ä¸šåç§°
2. è”ç³»ç”µè¯ä¼˜å…ˆæå–æ‰‹æœºå·ç 
3. äº§å“å“ç±»å¿…é¡»ä»ç»™å®šé€‰é¡¹ä¸­é€‰æ‹©æœ€åŒ¹é…çš„
4. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰æ˜ç¡®ä¿¡æ¯ï¼Œè®¾ç½®ä¸ºnull
5. è¿”å›æ ¼å¼å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSON

è¯·è¿”å›æå–ç»“æœï¼š"""

        return prompt

    def _build_detailed_info_prompt(self, content: str, merchant_type: str, current_data: Dict[str, Any] = None) -> str:
        """æ„å»ºè¯¦ç»†ä¿¡æ¯é˜¶æ®µçš„æç¤ºè¯"""

        merchant_type_name = self.merchant_type_names.get(merchant_type, merchant_type)

        current_info = ""
        if current_data:
            current_info = f"\nå½“å‰å·²å¡«å†™çš„ä¿¡æ¯ï¼š\n{json.dumps(current_data, ensure_ascii=False, indent=2)}\n"

        base_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å•†å®¶ç”³è¯·ä¿¡æ¯æå–åŠ©æ‰‹ã€‚è¯·ä»ä»¥ä¸‹æ–‡æ¡£å†…å®¹ä¸­æå–{merchant_type_name}çš„è¯¦ç»†ä¿¡æ¯ã€‚

å•†å®¶ç±»å‹ï¼š{merchant_type_name}

æ–‡æ¡£å†…å®¹ï¼š
{content[:3000]}
{current_info}"""

        # æ ¹æ®å•†å®¶ç±»å‹æ„å»ºä¸åŒçš„æç¤ºè¯
        if merchant_type == "factory":
            return self._build_factory_prompt(base_prompt)
        elif merchant_type == "brand":
            return self._build_brand_prompt(base_prompt)
        elif merchant_type == "agent":
            return self._build_agent_prompt(base_prompt)
        elif merchant_type == "dealer":
            return self._build_dealer_prompt(base_prompt)
        elif merchant_type == "operator":
            return self._build_operator_prompt(base_prompt)
        else:
            return self._build_generic_prompt(base_prompt)

    def _build_factory_prompt(self, base_prompt: str) -> str:
        """æ„å»ºå·¥å‚ç±»å‹çš„è¯¦ç»†æç¤ºè¯"""
        return base_prompt + """

è¯·æå–ä»¥ä¸‹å·¥å‚ç‰¹æœ‰å­—æ®µä¿¡æ¯ï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ï¼š

{
    "company_description": "å…¬å¸ç®€ä»‹",
    "specific_products": "å…·ä½“äº§å“",
    "own_brand": "è‡ªæœ‰å“ç‰Œï¼ˆæ²¡æœ‰å¡«æ— ï¼Œæœ‰å°±å¡«å†™å…·ä½“å“ç‰Œåç§°ï¼‰",
    "own_brand_operation_ability": "è‡ªæœ‰å“ç‰Œè¿è¥èƒ½åŠ›ï¼ˆæ²¡æœ‰å¡«æ— ï¼ŒæŒ‡åº—é“ºè¿è¥ã€å®¢æœã€ç‰©æµç­‰èƒ½åŠ›ï¼‰",
    "oem_famous_brands": "ä»£å·¥çš„çŸ¥åå“ç‰Œï¼ˆå¡«å†™å…·ä½“å“ç‰Œåç§°ï¼‰",
    "annual_production_capacity": "å¹´ç”Ÿäº§è§„æ¨¡ï¼ˆäº§èƒ½ä¼˜åŠ¿ï¼Œæœ€å¤§äº§å‡ºèƒ½åŠ›ï¼‰",
    "need_mold_or_repackage": "æ˜¯å¦éœ€è¦å¼€æ¨¡æˆ–æ”¹åŒ…è£…ï¼ˆæ˜¯/å¦/æœªç¡®è®¤ï¼‰",
    "estimated_mold_time": "é¢„è®¡å¼€æ¨¡/æ”¹åŒ…è£…æ—¶é—´ï¼ˆç¤ºä¾‹ï¼šxå¤©ã€xä¸ªæœˆï¼‰",
    "accept_brand_cocreation": "æ˜¯å¦æ¥å—å“ç‰Œå…±åˆ›ï¼ˆæ˜¯/å¦ï¼Œå“ç‰Œå±äºé¥æœ›æˆ–é¥æœ›åˆèµ„å…¬å¸ï¼‰",
    "accept_deep_cooperation": "æ˜¯å¦æ¥å—æ·±åº¦åˆä½œï¼ˆæ˜¯/å¦ï¼‰",
    "accept_online_exclusive": "æ˜¯å¦æ¥å—çº¿ä¸Š/å…¨æ¸ é“ç‹¬å®¶ï¼ˆæ˜¯/å¦ï¼‰",
    "accept_yaowang_authorization": "æ˜¯å¦æ¥å—é¥æœ›æˆæƒå…¶ä»–æ¸ é“ï¼ˆæ˜¯/å¦ï¼‰",
    "accept_omnichannel_dividend": "æ˜¯å¦æ¥å—åç»­å…¨æ¸ é“åˆ†çº¢ï¼ˆæ˜¯/å¦ï¼‰"
}

æå–è¦æ±‚ï¼š
1. é‡ç‚¹å…³æ³¨ç”Ÿäº§èƒ½åŠ›ã€ä»£å·¥ç»éªŒã€åˆä½œæ„æ„¿
2. å¯¹äºæ˜¯/å¦é—®é¢˜ï¼Œå°½é‡ä»æ–‡æ¡£ä¸­æ¨æ–­æ€åº¦
3. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰æ˜ç¡®ä¿¡æ¯ï¼Œè®¾ç½®ä¸ºnull
4. è¿”å›æ ¼å¼å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSON

è¯·è¿”å›æå–ç»“æœï¼š"""

    def _build_brand_prompt(self, base_prompt: str) -> str:
        """æ„å»ºå“ç‰Œå•†ç±»å‹çš„è¯¦ç»†æç¤ºè¯"""
        return base_prompt + """

è¯·æå–ä»¥ä¸‹å“ç‰Œå•†ç‰¹æœ‰å­—æ®µä¿¡æ¯ï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ï¼š

{
    "company_description": "å…¬å¸ç®€ä»‹",
    "brand_name": "å“ç‰Œåç§°ï¼ˆå¡«å†™å…·ä½“å“ç‰Œåç§°ï¼‰",
    "brand_popularity": "å“ç‰ŒçŸ¥ååº¦ï¼ˆå¯ä¸Šä¼ ç¬¬ä¸‰æ–¹å¹³å°åº—é“ºé¦–é¡µæˆªå›¾ï¼‰",
    "sales_data": "é”€å”®æ•°æ®ï¼ˆçº¿ä¸Šé”€å”®ã€åº—é“ºè‡ªæ’­ã€çº¿ä¸‹å•†è¶…é”€å”®æ•°æ®ï¼‰",
    "cooperation_budget": "åˆä½œé¢„ç®—ï¼ˆæ—¥å¸¸é”€å”®æˆ–è¥é”€é¢„ç®—æŠ•å…¥ï¼‰"
}

æå–è¦æ±‚ï¼š
1. é‡ç‚¹å…³æ³¨å“ç‰Œå½±å“åŠ›ã€é”€å”®è¡¨ç°ã€è¥é”€æŠ•å…¥
2. é”€å”®æ•°æ®è¦å…·ä½“ï¼ŒåŒ…å«å¹³å°ã€é‡‘é¢ã€æ—¶é—´ç­‰
3. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰æ˜ç¡®ä¿¡æ¯ï¼Œè®¾ç½®ä¸ºnull
4. è¿”å›æ ¼å¼å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSON

è¯·è¿”å›æå–ç»“æœï¼š"""

    def _build_agent_prompt(self, base_prompt: str) -> str:
        """æ„å»ºä»£ç†å•†ç±»å‹çš„è¯¦ç»†æç¤ºè¯"""
        return base_prompt + """

è¯·æå–ä»¥ä¸‹ä»£ç†å•†ç‰¹æœ‰å­—æ®µä¿¡æ¯ï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ï¼š

{
    "company_description": "å…¬å¸ç®€ä»‹",
    "agent_brand_name": "ä»£ç†çš„å“ç‰Œåç§°ï¼ˆæ²¡æœ‰å¡«æ— ï¼Œæœ‰å°±å¡«å†™ä»£ç†å“ç‰Œåç§°ï¼‰",
    "brand_popularity": "å“ç‰ŒçŸ¥ååº¦ï¼ˆå¯ä¸Šä¼ ç¬¬ä¸‰æ–¹å¹³å°åº—é“ºé¦–é¡µæˆªå›¾ï¼‰",
    "sales_data": "é”€å”®æ•°æ®ï¼ˆçº¿ä¸Šé”€å”®ã€å†å²åˆä½œä¸»æ’­ã€çº¿ä¸‹å•†è¶…é”€å”®æ•°æ®ï¼‰",
    "cooperation_budget": "åˆä½œé¢„ç®—ï¼ˆæ—¥å¸¸é”€å”®æˆ–è¥é”€é¢„ç®—æŠ•å…¥ï¼‰"
}

æå–è¦æ±‚ï¼š
1. é‡ç‚¹å…³æ³¨ä»£ç†å“ç‰Œå®åŠ›ã€æ¸ é“èƒ½åŠ›ã€åˆä½œç»éªŒ
2. é”€å”®æ•°æ®è¦ä½“ç°ä»£ç†èƒ½åŠ›å’Œå¸‚åœºè¡¨ç°
3. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰æ˜ç¡®ä¿¡æ¯ï¼Œè®¾ç½®ä¸ºnull
4. è¿”å›æ ¼å¼å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSON

è¯·è¿”å›æå–ç»“æœï¼š"""

    def _build_dealer_prompt(self, base_prompt: str) -> str:
        """æ„å»ºç»é”€å•†ç±»å‹çš„è¯¦ç»†æç¤ºè¯"""
        return base_prompt + """

è¯·æå–ä»¥ä¸‹ç»é”€å•†ç‰¹æœ‰å­—æ®µä¿¡æ¯ï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ï¼š

{
    "company_description": "å…¬å¸ç®€ä»‹",
    "dealer_brand_name": "ç»é”€çš„å“ç‰Œåç§°ï¼ˆæ²¡æœ‰å¡«æ— ï¼Œæœ‰å°±å¡«å†™ç»é”€å“ç‰Œåç§°ï¼‰",
    "brand_popularity": "å“ç‰ŒçŸ¥ååº¦ï¼ˆå¯ä¸Šä¼ ç¬¬ä¸‰æ–¹å¹³å°åº—é“ºé¦–é¡µæˆªå›¾ï¼‰",
    "sales_data": "é”€å”®æ•°æ®ï¼ˆçº¿ä¸Šé”€å”®ã€å†å²åˆä½œä¸»æ’­ã€çº¿ä¸‹å•†è¶…é”€å”®æ•°æ®ï¼‰",
    "cooperation_budget": "åˆä½œé¢„ç®—ï¼ˆæ—¥å¸¸é”€å”®æˆ–è¥é”€é¢„ç®—æŠ•å…¥ï¼‰"
}

æå–è¦æ±‚ï¼š
1. é‡ç‚¹å…³æ³¨ç»é”€å“ç‰Œã€åˆ†é”€ç½‘ç»œã€é”€å”®èƒ½åŠ›
2. é”€å”®æ•°æ®è¦ä½“ç°ç»é”€å®åŠ›å’Œå¸‚åœºè¦†ç›–
3. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰æ˜ç¡®ä¿¡æ¯ï¼Œè®¾ç½®ä¸ºnull
4. è¿”å›æ ¼å¼å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSON

è¯·è¿”å›æå–ç»“æœï¼š"""

    def _build_operator_prompt(self, base_prompt: str) -> str:
        """æ„å»ºä»£è¿è¥å•†ç±»å‹çš„è¯¦ç»†æç¤ºè¯"""
        return base_prompt + """

è¯·æå–ä»¥ä¸‹ä»£è¿è¥å•†ç‰¹æœ‰å­—æ®µä¿¡æ¯ï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ï¼š

{
    "company_description": "å…¬å¸ç®€ä»‹",
    "operator_brand_name": "ä»£è¿è¥çš„å“ç‰Œåç§°ï¼ˆå¡«å†™ä»£è¿è¥çš„å“ç‰Œåç§°ï¼‰",
    "brand_popularity": "å“ç‰ŒçŸ¥ååº¦ï¼ˆå¯ä¸Šä¼ ç¬¬ä¸‰æ–¹å¹³å°åº—é“ºé¦–é¡µæˆªå›¾ï¼‰",
    "sales_data": "é”€å”®æ•°æ®ï¼ˆçº¿ä¸Šé”€å”®ã€åº—é“ºè‡ªæ’­ã€çº¿ä¸‹å•†è¶…é”€å”®æ•°æ®ï¼‰",
    "cooperation_budget": "åˆä½œé¢„ç®—ï¼ˆè¿‘æœŸæ—¥å¸¸é”€å”®æˆ–è¥é”€é¢„ç®—å¯æŠ•å…¥çš„å…·ä½“é‡‘é¢ï¼‰"
}

æå–è¦æ±‚ï¼š
1. é‡ç‚¹å…³æ³¨è¿è¥èƒ½åŠ›ã€æœåŠ¡å“ç‰Œã€è¿è¥æˆæœ
2. é”€å”®æ•°æ®è¦ä½“ç°è¿è¥æ•ˆæœå’Œä¸“ä¸šæ°´å¹³
3. åˆä½œé¢„ç®—è¦å…·ä½“åˆ°é‡‘é¢
4. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰æ˜ç¡®ä¿¡æ¯ï¼Œè®¾ç½®ä¸ºnull
5. è¿”å›æ ¼å¼å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSON

è¯·è¿”å›æå–ç»“æœï¼š"""

    def _build_generic_prompt(self, base_prompt: str) -> str:
        """æ„å»ºé€šç”¨ç±»å‹çš„è¯¦ç»†æç¤ºè¯"""
        return base_prompt + """

è¯·æå–ä»¥ä¸‹é€šç”¨å­—æ®µä¿¡æ¯ï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ï¼š

{
    "company_description": "å…¬å¸ç®€ä»‹",
    "business_scope": "ç»è¥èŒƒå›´",
    "cooperation_budget": "åˆä½œé¢„ç®—"
}

æå–è¦æ±‚ï¼š
1. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰æ˜ç¡®ä¿¡æ¯ï¼Œè®¾ç½®ä¸ºnull
2. è¿”å›æ ¼å¼å¿…é¡»æ˜¯æœ‰æ•ˆçš„JSON

è¯·è¿”å›æå–ç»“æœï¼š"""

    async def _call_llm(self, prompt: str) -> str:
        """è°ƒç”¨LLM API"""
        try:
            logger.info(f"è°ƒç”¨æœ¬åœ°LLMæ¨¡å‹: {self.model}")
            logger.info(f"æœåŠ¡åœ°å€: {self.client.base_url}")
            logger.info(f"æç¤ºè¯é•¿åº¦: {len(prompt)} å­—ç¬¦")

            # æ‰“å°å®Œæ•´çš„æç¤ºè¯
            print(f"\nğŸ¤– LLMè¾“å…¥æç¤ºè¯:")
            print("=" * 80)
            print(prompt)
            print("=" * 80)

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£ä¿¡æ¯æå–åŠ©æ‰‹ï¼Œæ“…é•¿ä»å„ç§å•†ä¸šæ–‡æ¡£ä¸­å‡†ç¡®æå–ç»“æ„åŒ–ä¿¡æ¯ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ç»“æœã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=self.temperature,
                max_tokens=self.max_tokens,
                stream=False
            )

            result = response.choices[0].message.content
            logger.info(f"LLMå“åº”é•¿åº¦: {len(result)} å­—ç¬¦")

            # æ‰“å°å®Œæ•´çš„LLMå“åº”
            print(f"\nğŸ¤– LLMåŸå§‹å“åº”:")
            print("=" * 80)
            print(result)
            print("=" * 80)

            return result

        except Exception as e:
            logger.error(f"LLM APIè°ƒç”¨å¤±è´¥: {e}")
            logger.error(f"æ¨¡å‹: {self.model}, æœåŠ¡åœ°å€: {self.client.base_url}")
            raise
    
    def _parse_basic_info_response(self, response: str) -> List[Dict[str, Any]]:
        """è§£æåŸºç¡€ä¿¡æ¯é˜¶æ®µçš„LLMå“åº”"""
        try:
            data = self._extract_json_from_response(response)
            if not data:
                return []

            # åŸºç¡€ä¿¡æ¯å­—æ®µæ˜ å°„å’ŒéªŒè¯
            basic_fields = {
                "company_name": {"required": True, "type": "text"},
                "contact_name": {"required": True, "type": "text"},
                "contact_phone": {"required": True, "type": "phone"},
                "contact_email": {"required": False, "type": "email"},
                "product_category": {"required": True, "type": "select"},
                "specific_products": {"required": True, "type": "text"},
                "cooperation_requirements": {"required": False, "type": "textarea"},
                "industry_operator_contact": {"required": False, "type": "text"}
            }

            suggestions = []
            for field_name, field_config in basic_fields.items():
                if field_name in data and data[field_name] is not None and data[field_name] != "":
                    value = data[field_name]
                    confidence = self._calculate_field_confidence(field_name, value, field_config)

                    suggestions.append({
                        "field_name": field_name,
                        "suggested_value": str(value),
                        "confidence": confidence,
                        "source": "llm",
                        "stage": "basic_info"
                    })

            logger.info(f"åŸºç¡€ä¿¡æ¯è§£æå®Œæˆï¼Œæå–äº† {len(suggestions)} ä¸ªå­—æ®µ")

            # æ‰“å°è§£æç»“æœ
            print(f"\nğŸ“‹ åŸºç¡€ä¿¡æ¯è§£æç»“æœ:")
            print("=" * 60)
            for suggestion in suggestions:
                print(f"  {suggestion['field_name']}: {suggestion['suggested_value']} (ç½®ä¿¡åº¦: {suggestion['confidence']:.2f})")
            print("=" * 60)

            return suggestions

        except Exception as e:
            logger.error(f"åŸºç¡€ä¿¡æ¯å“åº”è§£æå¤±è´¥: {e}")
            return []

    def _parse_detailed_info_response(self, response: str, merchant_type: str) -> List[Dict[str, Any]]:
        """è§£æè¯¦ç»†ä¿¡æ¯é˜¶æ®µçš„LLMå“åº”"""
        try:
            data = self._extract_json_from_response(response)
            if not data:
                return []

            # è·å–å•†å®¶ç±»å‹ç‰¹å®šå­—æ®µé…ç½®
            detailed_fields = self._get_merchant_type_fields(merchant_type)

            suggestions = []
            for field_name, field_config in detailed_fields.items():
                if field_name in data and data[field_name] is not None and data[field_name] != "":
                    value = data[field_name]
                    confidence = self._calculate_field_confidence(field_name, value, field_config)

                    suggestions.append({
                        "field_name": field_name,
                        "suggested_value": str(value),
                        "confidence": confidence,
                        "source": "llm",
                        "stage": "detailed_info",
                        "merchant_type": merchant_type
                    })

            logger.info(f"è¯¦ç»†ä¿¡æ¯è§£æå®Œæˆï¼Œæå–äº† {len(suggestions)} ä¸ªå­—æ®µ")

            # æ‰“å°è§£æç»“æœ
            print(f"\nğŸ“‹ è¯¦ç»†ä¿¡æ¯è§£æç»“æœ ({merchant_type}):")
            print("=" * 60)
            for suggestion in suggestions:
                print(f"  {suggestion['field_name']}: {suggestion['suggested_value']} (ç½®ä¿¡åº¦: {suggestion['confidence']:.2f})")
            print("=" * 60)

            return suggestions

        except Exception as e:
            logger.error(f"è¯¦ç»†ä¿¡æ¯å“åº”è§£æå¤±è´¥: {e}")
            return []

    def _extract_json_from_response(self, response: str) -> Dict[str, Any]:
        """ä»LLMå“åº”ä¸­æå–JSONæ•°æ®"""
        try:
            response_clean = response.strip()

            # æŸ¥æ‰¾JSONä»£ç å—
            if "```json" in response_clean:
                start = response_clean.find("```json") + 7
                end = response_clean.find("```", start)
                if end != -1:
                    response_clean = response_clean[start:end].strip()
            elif "{" in response_clean and "}" in response_clean:
                # æå–æ‰€æœ‰å®Œæ•´çš„JSONå¯¹è±¡ï¼Œé€‰æ‹©æœ€å¤§çš„ä¸€ä¸ªï¼ˆé€šå¸¸æ˜¯æœ€å®Œæ•´çš„ç»“æœï¼‰
                json_objects = []
                i = 0
                while i < len(response_clean):
                    start = response_clean.find("{", i)
                    if start == -1:
                        break

                    brace_count = 0
                    end = start
                    for j, char in enumerate(response_clean[start:], start):
                        if char == "{":
                            brace_count += 1
                        elif char == "}":
                            brace_count -= 1
                            if brace_count == 0:
                                end = j + 1
                                break

                    if brace_count == 0:  # æ‰¾åˆ°å®Œæ•´çš„JSONå¯¹è±¡
                        json_str = response_clean[start:end]
                        try:
                            json_obj = json.loads(json_str)
                            json_objects.append((json_str, json_obj, len(json_str)))
                        except json.JSONDecodeError:
                            pass  # å¿½ç•¥æ— æ•ˆçš„JSON

                    i = start + 1

                # é€‰æ‹©æœ€é•¿çš„JSONå¯¹è±¡ï¼ˆé€šå¸¸æ˜¯æœ€å®Œæ•´çš„ç»“æœï¼‰
                if json_objects:
                    json_objects.sort(key=lambda x: x[2], reverse=True)  # æŒ‰é•¿åº¦æ’åº
                    response_clean = json_objects[0][0]
                    logger.info(f"æ‰¾åˆ° {len(json_objects)} ä¸ªJSONå¯¹è±¡ï¼Œé€‰æ‹©æœ€é•¿çš„ä¸€ä¸ª")
                else:
                    logger.warning("æœªæ‰¾åˆ°æœ‰æ•ˆçš„JSONå¯¹è±¡")
                    return {}

            logger.info(f"æ¸…ç†åçš„JSON: {response_clean[:200]}...")
            return json.loads(response_clean)

        except json.JSONDecodeError as e:
            logger.error(f"JSONè§£æå¤±è´¥: {e}")
            logger.error(f"åŸå§‹å“åº”: {response}")
            return {}
        except Exception as e:
            logger.error(f"JSONæå–å¤±è´¥: {e}")
            return {}

    def _get_merchant_type_fields(self, merchant_type: str) -> Dict[str, Dict[str, Any]]:
        """è·å–å•†å®¶ç±»å‹ç‰¹å®šå­—æ®µé…ç½®"""
        common_fields = {
            "company_description": {"required": True, "type": "textarea"},
        }

        type_specific_fields = {
            "factory": {
                "specific_products": {"required": True, "type": "text"},
                "own_brand": {"required": False, "type": "text"},
                "own_brand_operation_ability": {"required": False, "type": "text"},
                "oem_famous_brands": {"required": False, "type": "text"},
                "annual_production_capacity": {"required": True, "type": "text"},
                "need_mold_or_repackage": {"required": False, "type": "radio"},
                "estimated_mold_time": {"required": False, "type": "text"},
                "accept_brand_cocreation": {"required": True, "type": "radio"},
                "accept_deep_cooperation": {"required": True, "type": "radio"},
                "accept_online_exclusive": {"required": True, "type": "radio"},
                "accept_yaowang_authorization": {"required": True, "type": "radio"},
                "accept_omnichannel_dividend": {"required": True, "type": "radio"}
            },
            "brand": {
                "brand_name": {"required": True, "type": "text"},
                "brand_popularity": {"required": False, "type": "textarea"},
                "sales_data": {"required": False, "type": "textarea"},
                "cooperation_budget": {"required": False, "type": "text"}
            },
            "agent": {
                "agent_brand_name": {"required": False, "type": "text"},
                "brand_popularity": {"required": False, "type": "textarea"},
                "sales_data": {"required": False, "type": "textarea"},
                "cooperation_budget": {"required": False, "type": "text"}
            },
            "dealer": {
                "dealer_brand_name": {"required": False, "type": "text"},
                "brand_popularity": {"required": False, "type": "textarea"},
                "sales_data": {"required": False, "type": "textarea"},
                "cooperation_budget": {"required": False, "type": "text"}
            },
            "operator": {
                "operator_brand_name": {"required": True, "type": "text"},
                "brand_popularity": {"required": False, "type": "textarea"},
                "sales_data": {"required": False, "type": "textarea"},
                "cooperation_budget": {"required": False, "type": "text"}
            }
        }

        # åˆå¹¶é€šç”¨å­—æ®µå’Œç‰¹å®šå­—æ®µ
        fields = {**common_fields}
        if merchant_type in type_specific_fields:
            fields.update(type_specific_fields[merchant_type])

        return fields

    def _calculate_field_confidence(self, field_name: str, value: str, field_config: Dict[str, Any]) -> float:
        """è®¡ç®—å•ä¸ªå­—æ®µçš„ç½®ä¿¡åº¦"""
        base_confidence = 0.7

        # æ ¹æ®å­—æ®µç±»å‹è°ƒæ•´ç½®ä¿¡åº¦
        field_type = field_config.get("type", "text")

        if field_type == "phone":
            # éªŒè¯ç”µè¯å·ç æ ¼å¼
            if self._validate_phone(value):
                base_confidence += 0.2
            else:
                base_confidence -= 0.3

        elif field_type == "email":
            # éªŒè¯é‚®ç®±æ ¼å¼
            if self._validate_email(value):
                base_confidence += 0.2
            else:
                base_confidence -= 0.3

        elif field_type == "radio":
            # å•é€‰å­—æ®µï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆé€‰é¡¹
            if value.lower() in ["æ˜¯", "å¦", "yes", "no", "true", "false", "æœªç¡®è®¤"]:
                base_confidence += 0.1
            else:
                base_confidence -= 0.2

        elif field_type == "select":
            # é€‰æ‹©å­—æ®µï¼Œæ£€æŸ¥é•¿åº¦å’Œå†…å®¹
            if len(value) > 2 and len(value) < 50:
                base_confidence += 0.1

        # æ ¹æ®å†…å®¹é•¿åº¦è°ƒæ•´ç½®ä¿¡åº¦
        if field_type in ["text", "textarea"]:
            if len(value) < 2:
                base_confidence -= 0.3
            elif len(value) > 100:
                base_confidence += 0.1

        # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®è¯
        if field_name in ["company_name", "brand_name"] and any(keyword in value for keyword in ["æœ‰é™å…¬å¸", "è‚¡ä»½", "é›†å›¢", "ç§‘æŠ€", "å®ä¸š"]):
            base_confidence += 0.1

        # ç¡®ä¿ç½®ä¿¡åº¦åœ¨åˆç†èŒƒå›´å†…
        return max(0.1, min(1.0, base_confidence))

    def _calculate_overall_confidence(self, suggestions: List[Dict[str, Any]]) -> float:
        """è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦"""
        if not suggestions:
            return 0.0
        
        total_confidence = sum(s.get("confidence", 0) for s in suggestions)
        return total_confidence / len(suggestions)
    
    async def validate_suggestions(self, suggestions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """éªŒè¯å’Œä¼˜åŒ–å»ºè®®"""
        try:
            validated_suggestions = []
            for suggestion in suggestions:
                field_name = suggestion["field_name"]

                # è¿‡æ»¤æ‰ç½®ä¿¡åº¦è¿‡ä½çš„å»ºè®®
                if suggestion["confidence"] >= 0.3:
                    validated_suggestions.append(suggestion)
                else:
                    logger.warning(f"è¿‡æ»¤ä½ç½®ä¿¡åº¦å­—æ®µ: {field_name} (ç½®ä¿¡åº¦: {suggestion['confidence']})")

            return validated_suggestions

        except Exception as e:
            logger.error(f"å»ºè®®éªŒè¯å¤±è´¥: {e}")
            return suggestions

    async def detect_merchant_type(self, content: str) -> str:
        """
        æ ¹æ®æ–‡æ¡£å†…å®¹è‡ªåŠ¨æ£€æµ‹å•†å®¶ç±»å‹
        """
        try:
            content_lower = content.lower()

            # å·¥å‚ç±»å‹å…³é”®è¯
            factory_keywords = ['ç”Ÿäº§', 'åˆ¶é€ ', 'å·¥å‚', 'äº§èƒ½', 'ç”Ÿäº§çº¿', 'ä»£å·¥', 'oem', 'å¹´äº§', 'äº§é‡', 'è½¦é—´', 'è®¾å¤‡']
            # å“ç‰Œå•†å…³é”®è¯
            brand_keywords = ['å“ç‰Œ', 'å•†æ ‡', 'è‡ªæœ‰å“ç‰Œ', 'å“ç‰Œæ¨å¹¿', 'å“ç‰Œè¥é”€', 'çŸ¥ååº¦', 'å“ç‰Œä»·å€¼', 'å“ç‰Œå½±å“åŠ›']
            # ä»£ç†å•†å…³é”®è¯
            agent_keywords = ['ä»£ç†', 'ç»é”€', 'åˆ†é”€', 'æ¸ é“', 'ä»£ç†æƒ', 'ç»é”€å•†', 'æˆæƒ', 'ä»£ç†å•†']
            # ä»£è¿è¥å…³é”®è¯
            operator_keywords = ['ä»£è¿è¥', 'è¿è¥', 'æ‰˜ç®¡', 'ä»£ç†è¿è¥', 'ç”µå•†è¿è¥', 'åº—é“ºè¿è¥', 'å¹³å°è¿è¥']

            factory_score = sum(1 for keyword in factory_keywords if keyword in content_lower)
            brand_score = sum(1 for keyword in brand_keywords if keyword in content_lower)
            agent_score = sum(1 for keyword in agent_keywords if keyword in content_lower)
            operator_score = sum(1 for keyword in operator_keywords if keyword in content_lower)

            logger.info(f"å•†å®¶ç±»å‹è¯„åˆ† - å·¥å‚:{factory_score}, å“ç‰Œ:{brand_score}, ä»£ç†:{agent_score}, ä»£è¿è¥:{operator_score}")

            # è¿”å›å¾—åˆ†æœ€é«˜çš„ç±»å‹
            scores = {
                "factory": factory_score,
                "brand": brand_score,
                "agent": agent_score,
                "operator": operator_score
            }

            max_type = max(scores, key=scores.get)
            max_score = scores[max_type]

            # å¦‚æœæœ€é«˜åˆ†æ•°å¤ªä½ï¼Œé»˜è®¤è¿”å›å·¥å‚ç±»å‹
            if max_score < 2:
                logger.info("æ‰€æœ‰ç±»å‹å¾—åˆ†éƒ½è¾ƒä½ï¼Œé»˜è®¤æ¨èå·¥å‚ç±»å‹")
                return "factory"

            logger.info(f"æ¨èå•†å®¶ç±»å‹: {max_type} (å¾—åˆ†: {max_score})")
            return max_type

        except Exception as e:
            logger.error(f"å•†å®¶ç±»å‹æ£€æµ‹å¤±è´¥: {e}")
            return "factory"  # é»˜è®¤è¿”å›å·¥å‚ç±»å‹
    
    def _validate_phone(self, phone: str) -> bool:
        """éªŒè¯ç”µè¯å·ç æ ¼å¼"""
        import re
        # ç®€å•çš„ä¸­å›½æ‰‹æœºå·éªŒè¯
        pattern = r'^1[3-9]\d{9}$'
        return bool(re.match(pattern, phone.replace(' ', '').replace('-', '')))
    
    def _validate_email(self, email: str) -> bool:
        """éªŒè¯é‚®ç®±æ ¼å¼"""
        import re
        pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
        return bool(re.match(pattern, email))

# åˆ›å»ºå…¨å±€LLMæœåŠ¡å®ä¾‹
llm_service = LLMService()
